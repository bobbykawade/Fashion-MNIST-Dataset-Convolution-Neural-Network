{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading libraries\n",
    "!pip install imutils\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fashion MNIST dataset is identical to the MNIST dataset in terms of training set size, testing set size, \n",
    "number of class labels, and image dimensions:\n",
    "60,000 training examples\n",
    "10,000 testing examples\n",
    "10 classes\n",
    "28Ã—28 grayscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/\n",
    "#Building the class\n",
    "class Structure_CNN:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes): #Image parameters\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "        #Setting default value of Channel\n",
    "\t\tchanDim = -1\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "        # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "        #Filter = 32\n",
    "        #Kernel = 3,3\n",
    "        # padding in order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences.\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "        #Activatation function\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "        #Batch normalization applies a transformation that maintains the mean output close to 0 \n",
    "        #and the output standard deviation close to 1.\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "        #Dense implements the operation: output = activation(dot(input, kernel) + bias) \n",
    "        #where activation is the element-wise activation function passed as the activation argument, \n",
    "        #kernel is a weights matrix created by the layer, and \n",
    "        #bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
    "\t\tmodel.add(Dense(512))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5)) #The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "        #For multi class output we are using softmax\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from sklearn.metrics import classification_report #Evaluation Matrix report\n",
    "from tensorflow.keras.optimizers import SGD #Stocastic Gradient Boosting \n",
    "from tensorflow.keras.datasets import fashion_mnist #Dataset\n",
    "from tensorflow.keras.utils import to_categorical #Transformation\n",
    "from tensorflow.keras import backend as K #Interact with tensorflow in backend\n",
    "from imutils import build_montages  #to show multiple images in opencv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 #For opencv\n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 2 #Number of epoch\n",
    "INIT_LR = 1e-2 #Learning Rate\n",
    "BS = 32 #Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n"
     ]
    }
   ],
   "source": [
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "# if we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# \tnum_samples x depth x rows x columns\n",
    "#Channel_first means - Channel information is going in beginning after batch size\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "\ttestX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    " \n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "    # scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "# one-hot encode the training and testing labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "# initialize the names of the class\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 278s 148ms/step - loss: 0.5391 - accuracy: 0.8125 - val_loss: 0.3540 - val_accuracy: 0.8739\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 278s 148ms/step - loss: 0.3848 - accuracy: 0.8597 - val_loss: 0.3189 - val_accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "#Applying Stocastic Gradient Descent\n",
    "#momentum = method which helps accelerate gradients vectors in the right directions, thus leading to faster converging\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS) #Applies exponential decay to the learning rate. \n",
    "#depth 1 means greyscale\n",
    "model = Structure_CNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(x=trainX, y=trainY,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tbatch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.84      0.85      0.84      1000\n",
      "     trouser       0.99      0.97      0.98      1000\n",
      "    pullover       0.81      0.84      0.83      1000\n",
      "       dress       0.88      0.90      0.89      1000\n",
      "        coat       0.79      0.82      0.80      1000\n",
      "      sandal       0.99      0.95      0.97      1000\n",
      "       shirt       0.71      0.65      0.68      1000\n",
      "     sneaker       0.92      0.97      0.95      1000\n",
      "         bag       0.97      0.97      0.97      1000\n",
      "  ankle boot       0.96      0.95      0.96      1000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "#argmax give the position where we get maximum value\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1),\n",
    "\ttarget_names=labelNames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-ca1993d21610>:14: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"D:\\\\RecogX_Backup\\\\EL\\\\DeepLearning\\\\plot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize our list of output images\n",
    "images = []\n",
    "# randomly select a few testing fashion items\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "\t# classify the clothing\n",
    "\tprobs = model.predict(testX[np.newaxis, i])\n",
    "\tprediction = probs.argmax(axis=1)\n",
    "\tlabel = labelNames[prediction[0]]\n",
    " \n",
    "\t# extract the image from the testData if using \"channels_first\"\n",
    "\t# ordering\n",
    "\tif K.image_data_format() == \"channels_first\":\n",
    "\t\timage = (testX[i][0] * 255).astype(\"uint8\")\n",
    " \n",
    "\t# otherwise we are using \"channels_last\" ordering\n",
    "\telse:\n",
    "\t\timage = (testX[i] * 255).astype(\"uint8\")\n",
    "        # initialize the text label color as green (correct)\n",
    "\tcolor = (0, 255, 0)\n",
    "\t# otherwise, the class label prediction is incorrect\n",
    "\tif prediction[0] != np.argmax(testY[i]):\n",
    "\t\tcolor = (0,0,255)\n",
    "\n",
    " \n",
    "\t# merge the channels into one image and resize the image from\n",
    "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
    "\t# predicted label on the image\n",
    "\timage = cv2.merge([image] * 3)\n",
    "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "\t\tcolor, 2)\n",
    "\t# add the image to our list of output images\n",
    "\timages.append(image)\n",
    "# construct the montage for the images\n",
    "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
    "# show the output montage\n",
    "cv2.imshow(\"Fashion MNIST\", montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
